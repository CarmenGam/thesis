\documentclass[main.tex]{subfiles}

\begin{document}
\glsresetall

Along the scope of this thesis, I have contributed to the commissioning of the \gls{cta}, playing my small part to the very high energy $\gamma$-ray astrophysics field.\\
The prototype of the \gls{lst} is currently in its commissioning phase since December 2018, and since its beginning I have participated in several activities related to it. Half of the work done during this thesis has been destined to the development and verification of the software for the analysis of \gls{lst}1 data during single telescope operation. This software, currently in a very advanced version, allow to reduce the data taken by the telescope, from the raw level (R0), to the reconstruction of the primary particle information (energy, direction and distinction between $\gamma$s and hadrons, level DL2). The data reconstruction is made in several phases. In first place, the data recorded in each pixel is calibrated, doing the conversion between \gls{adc} counts and photoelectrons. Once the image of the Cherenkov shower is extracted, it is parameterized followig the Hillas method. These parameters, together with the arrival time of the light to each pixel, are used to reconstruct the energy, direction and type of particle making use of a set of \glspl{rf}, a machine learning method. My personal contribution to this task, has consisted in the writing and verification of the code for the analysis, specially in its initial versions. I have used the analysis chain, applied to Monte Carlo simulations, to obtain the performance of the telescope, which reaches an energy resolution of 20\% in the range from $\sim 100$ GeV to $\sim$ 1 TeV. About the angular resolution, it goes down to $\sim 0.2$ยบ in the same energy range. I have also computed the sensitivity of the telescope to the detection of a point source in 50 hours of observation time, which goes close to the 10\% of the Crab Nebula flux in the range from 100 GeV to 1 TeV. I have applied the same analysis chain to reconstruct real data recorded with the telescope during the three data taking campaigns, where a significance of 6-10$\sigma/\sqrt{h}$ has been reached for the detection of the Crab Nebula.\\
In addition, I have developed an alternative method for the calculation of the Hillas parameters based the \gls{em} algorithm, which do not require the application of a cleaning to the shower images, and therefore no tuning of cleaning parameters is needed. Using this method, the performance obtained regarding energy and angular resolution is in general, not as good as when applying the traditional tailcuts cleaning, except for the lower energies (below 200 GeV). On the other hand, it has shown a better performance in $\gamma$-hadron separation, even without making strong cuts in the intensity of the showers, which allow to recover a large number of low intensity $\gamma$ events. Performing the data reconstruction with \gls{em} and optimizing the $\gamma$-hadron separation, the best cut in gammaness is > 0.7. With this cut,  it is possible to recover up to a 40\% of $\gamma$ events, which with the traditional tailcuts cleaning method would be discarded. On the other hand, it has the caveat of missclassify 10\% more of hadrons for the same cut in gammaness, relative to the traditional method. Applying this method to the real data of the three Crab campaigns of \gls{lst}1 provided similar values of maximum detection significance as of the method with tailcuts cleaning, but applying a lower cut in intensity which allow to preserve more events, and reach higher $\gamma$ rates. Typically to obtain a good performance with the tailcuts cleaning method, it is required to discar showers with less than 500 or 1000 photoelectrons. As a consequence, the \gls{em} allows to preserve more showers with low energy, and therefore, lower the energy threshold of the telescope.\\ 
As a second part of the thesis, in which I have worked in paralell with the previous, I have participated in the \gls{ksp} of the \gls{lmc} for \gls{cta}. This project has more than 300 hours of observation assigned to a full galaxy survey, which pursues three main scientific goals: The study of the powerful $\gamma$-ray sources of the \gls{lmc} and the discovering of new ones, the study of cosmic-ray injection and propagation by the detection of the $\gamma$-ray diffuse emission in the \gls{lmc}; and the possible detection of a \gls{dm} annihilation signal in the galaxy. For this project, it has been necessary to create a model of the expected $\gamma$-ray emission from the \gls{lmc} in the energy range of \gls{cta}. The model computed includes four known point sources detected by current $\gamma$-ray telescopes, diffuse emission produced by \glspl{cr} interacting with the \gls{ism}, and a synthetic population of \gls{pwne}. The model has been given as input for a simulation of the data that would be obtained from the \gls{cta} \gls{lmc} survey, using the \gls{cta} software \textit{ctools}. This simulation has been then used to perform a binned likelihood analysis, fitting the simulated values to the model, in order to forsee the possibilities of \gls{cta} to detect and study the different $\gamma$-ray sources of the \gls{lmc}. The results show that the powerful known point sources will be detected with high significance, allowing to study their spectral features on the energy range from 100 GeV to 100 TeV. Also, at least around a ten of new sources of the \gls{pwn} type will be discovered by \gls{cta}. About the diffuse emission from \glspl{cr}, the model built to reproduce the leptonic component, as a result of \gls{ic} scattering of charged \glspl{cr}, seems to be too faint to be disentangled from the instrumental background. On the other hand, the hadronic component, produced by pion-decay, offers more optimistic results, with high significance values specially in regions with high gas density.\\
Besides the study of the astrophysical sources, the emission model and the results from the previously described analysis, have been used as background over which to study the possibilities of \gls{cta} to detect a signal from the annihilation of \gls{dm} composed by \glspl{wimp}. To do so, different models of \gls{dm} profiles in the \gls{lmc} have been tested, together with a set of different annihilation channels, typically used in the literature, to study the parameter space of annihilation cross section and \gls{dm} particle masses which could be probed by \gls{cta}. The results from this analysis show that, except for the models with very cuspy \gls{dm} profiles (yet unrealistic ones), \gls{cta} will not be able to rule out the tipical \gls{wimp} model of the canonical thermal cross section.\\
This work will serve as a baseline for the \gls{lmc} \gls{ksp}, opening the path for more detailed and realistic analysis. The next steps would be to perform a blind analysis of the point sources, with a detailed study of the spectral features which could be derived, include in the model the \gls{snr} 1987A, include a synthetic population of \glspl{snr}, etc.\\
The results from this work have been gathered in a \gls{cta} consortium paper, currently in preparation, for which I am one of the corresponding authors. 


\end{document}
