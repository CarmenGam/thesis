\documentclass[main.tex]{subfiles}
\begin{document}
\glsresetall

\section{Introduction}

The first \gls{lst} was inaugurated in October 2018 and since then has been in commissioning phase. Being the first \gls{cta} telescope installed on site (in La Palma island), and it is expected to be operating on its own until LST 2-4 are built. This mean that LST1 will need its own analysis chain in \textit{mono} mode, which differs in several aspecst from the stereo analysis included in the benchmark analysis tools of \gls{cta} (see section \ref{sec:ctapipe}). Although single telescope observations present a big challenge, specially regarding source position reconstruction and $\gamma$-hadron separation, it is expected that LST1 performance, thanks to its size and camera design, will be competitive enoughh to offer scientific results in the time it will be operating alone.\\
This chapter will present a considerable amount of the work done during this thesis, which includes the development of the code for the single telescope analysis for LST1, the calculation of LST1 sensitivity based on \gls{mc} simulations, the development of a new technique for Hillas Parameters calculation without cleaning using the Expectation-Maximization algorithm and the application of the analysis chain to real LST1 data. 

\section{The LST1 analysis chain overview}

The analysis software for the single telescope analysis of LST1 named \textit{cta-lstchain} has been developed before the necessity of specific tools for single telescope analysis not included in \textit{ctapipe}, the benchmark analysis tools for low level data of \gls{cta}. It is written as a python package which heavily relies on \textit{ctapipe}, and it is structured in several modules containing functions destined to the different parts of the analysis. The first version of \textit{cta-lstchain} was written by the author of this thesis and many contributors have joined the project over the last two years to improve and optimize the repository to its current version, which is able to perform every analysis step both for simulated \gls{mc} data and real data. The analysis chain is divided in several steps, each of which can be executed through a python script which requires certain inputs and calls for the appropriate functions. All the configuration parameters of the different elements of the analysis are given through configuration files, which can be edited by the user or else a standard configuration will be used. The input of the analysis chain are the raw data files of LST1 events, which for \gls{mc} data are \textit{sim$\_$telarray} files and for real data are \textit{zfits} files with a similar internal format. The files contain the full information available per pixel, known as \textit{waveform} and which is the digitized signal amplitude vs. time sample for every triggered event, together with \gls{mc} information in the case of a simulated file (such as the true energy, source position, number of simulated events, and so on), or recorded information from the different telescope subsystems in the case of real data (such as time, pointing, trigger type...). Throughout the analysis chain, the data including the images and image parameters, is stored in containers designed in \textit{cta-lstchain} specifically for LST1, which can be dumped into \textit{pandas} dataframes and saved in \textit{hdf5} files.\\
The main steps of the analysis chain can be summarized as: \\

\begin{itemize}
\item\textbf{Calibration:} The waveforms of each pixel in the camera should be integrated after pedestal subtraction, and converted to number of photoelectrons. Also, the timing information of the signal is obtained. 
\item\textbf{Image cleaning and parametrization:} The images in the camera contain pixels with light not related to the cherenkov event, so a cleaning must be applied to remove them. Afterwards, the photon distribution in the image is used to calculate the Hillas parameters.
\item\textbf{Energy and direction reconstruction:} The energy and direction reconstruction of the triggered events are performed using a multidimensional regresssion technique based on \glspl{rf}. A set of simulated diffuse $\gamma$ events are used to train the \gls{rf}. 
\item\textbf{$\gamma$-hadron separation:} For the $\gamma$-hadron separation, a multidimensional \gls{rf} classifier is used. Sets of simulated $gamma$ and proton events, which energies and directions have been reconstructed in the previous step, are used to train the classifier.
\end{itemize}

\subsection{Calibration}

In the calibration phase, the raw signal known as \textit{waveform} is integrated after background subtraction, to obtain a total number of counts per pixel, which afterwards is multiplied by a factor to be converted in number of photoelectrons. Depending on if \gls{mc} data or real data is being analyzed, the following steps vary and will be explained for each case.

\subsubsection{Signal extraction} \label{sec:signalext}

For every triggered event, the signal in each pixel is recorded in a 40 samples window from the 4096 samples \gls{dsr4}. This signal contains information not only from the Cherenkov light, but also from background light from \gls{nsb} and from the intrinsic noise induced by the readout chain. Before integrating the signal, it is necessary to subtract this \textit{pedestal}. For simulated \gls{mc} events the pedestal value for each pixel in the camera is already stored, but for real data it is necessary to take special pedestal runs, with randomly activated trigger. Pedestal events are used to calculate the mean pedestal value for each \gls{dsr4} sample so typically, around 1000 events are needed to fill the ring. In \textit{cta-lstchain} a specific script is used to extract the pedestal values from pedestal runs and they are stored in a \textit{hdf5} file to be used later in the calibration.\\
Once the pedestal is subtracted from the signal, the signal peak can be integrated. Typically a smaller window of a few samples around the maximum is used for the integration, which can be performed with one of the several integrators implemented in \textit{ctapipe}. By default, the integrator used in \textit{cta-lstchain} is the \textit{NeighborPeakWindowSum}, which sums the signal in a window around the peak defined by the waveform in neighbouring pixels. This allow to avoid integrating peaks which can arise from fluctuations. The default width of the integration window for this integrator is of 7 samples. When analyzing real data, the first and last two samples of the waveform should be dropped, to avoid integrating the spikes that can arise from ?? ¿¿. These calibration steps are performed for the two gain channels of \gls{lst}1 camera, if available. By default, the signal used is the high gain, unless it is saturated, meaning the maximum is above 4096 counts. In this case, the channel is switched to low gain for that pixel. 

\subsubsection{Conversion to photoelectrons}

Once the signal amplitude is extracted, it must be converted from DC counts to photoelectrons through a calibration factor, which is different for each pixel and channel. For simulated \gls{mc} data, these factors are stored in the simulated file and the conversion can be done simply by multiplying the image in DC counts by the factor of each pixel. For real data, special calibration runs must be taken to calculate these factors. Calibration events are taken using Ultraviolet light pulses fired from the CaliBox \cite{2015CaliBox}, \cite{2019CaliBox} located in the mirror dish. The calculation of the calibration coefficients is made using the F-factor method \cite{1997calibrationPMT}, which assumes that the distribution of photoelectrons in a \gls{pmt} follows a poissonian statistics with a mean $N$ and a \gls{rms} of $\sqrt{N}$. The signal distribution, however, will be deviated from a poissonian statistics with a wider \gls{rms} due to a excess-noise factor F, which is different for each \gls{pmt} and whould be measured in the laboratory. The relation between the relative widths of the two distributions can be written as:

\begin{equation}
  F \cdot \frac{1}{\sqrt{N}} = \frac{\sigma_{Q}}{<Q>}
  \label{eq:ffactor}
\end{equation} 

Where $<Q>$ is the mean value of the pixel signal and $\sigma_{Q}$ its \gls{rms}. The calibration coefficients will come from the relation between the number of photoelectrons $N$ and the mean pixel signal $<Q>$, which from \ref{eq:ffactor}, and taking into account that the signal must be corrected from pedestal:

\begin{equation}
  \frac{N}{<Q>} = F^{2}\frac{<Q> - <ped>}{\sigma_{Q}^{2} - \sigma_{ped}^{2}}
\end{equation}

The values of $<Q>$, $\sigma_{Q}$, $<ped>$ and $\sigma_{ped}$ are calaculated from a sufficiently large number ($\sim$ 1000) of calibration and pedestal events, using a specific script from \textit{cta-lstchain}, which stores the resulting calibration coefficients in an HDF5 file to be used later in the calibration of data runs. For the LST1, the value of F factor used is the mean value for all \gls{pmt} which is 1.2.

\subsection{Image cleaning and parametrization}

In order to extract information from the image of Cherenkov light shower recorded by the camera, it is necessary to get rid of the background light not belonging to the Cherenkov event, which has arrived to all pixels. This backgrund light is usually related to fluctuations in the \gls{nsb}. A process named cleaning is used to eliminate all pixels which presumably do not contain light from the shower and after the \textit{clean} image is the one used to perform the parametrization. Besides there exist several proposed cleaning algorithms in the literature \cite{2019cleaningCNN}, \cite{2013neighborcleaning}, \cite{2005Cleaningwithtimeinfo}, \cite{2001waveletcleaning}, for the time being in \textit{cta-lstchain}, a classical two-level tailcuts cleaning is being used (e.g. the used in \cite{1997HEGRAperformance}). This method uses only the information of the amount of light in pixels (already converted to number of photoelectrons) and compares it to two levels of thresholds in the following way:

\begin{itemize}

\item Pixels with a number of photoelectrons over the highest threshold level are selected.
\item If pixels selected in the previous step have at least one neighbor also above the highest level threshold, those pixels are marked as core pixels from the shower.

 \item Neighbors of the core pixels with number of photoelectrons above the lower level threshold are selected as boundary pixels. For the rest of them not selected, their charge is set to zero. 
\end{itemize}
   
   The stantdard values for the two levels used in \textit{cta-lstchain} are $Th_{high} = 10$ phes and $Th_{low} = 5$ phe, just the same values used by MAGIC telescopes. Note that these values have not been yet optimized for the particular case of the \gls{lst}1, and they can be changed easily in the configuration files. An optimization of the cleaning can lead to a better performance, specially for lower energies, because in those cases Cherenkov showers are small and a lot of information can be lost because of cleaning. Using other information apart from the number of photoelectrons, for example the arrival times of the signals to pixels, can help to improve the image parametrization. Low energy showers of $\gamma$s and hadrons are much more difficult to differentiate, for that reason, an image parametrization which highly depends on the settings of the cleaning parameters can be problematic when trying to lower the eneergy threshold of the telescope. In section \ref{sec:EM} a method for image parametrization not requiring previous cleaning is proposed as an alternative.\\
   The parametrization of the shower image after cleaning, that is to say the calculation of the Hillas parameters (see section \ref{sec:IACTs} and figure \ref{fig:hillas}), is performed by a specific function from \textit{ctapipe}. The resulting parameters: intensity (total number of photoelectrons in the shower)width, length, coordinates of ellipse center of gravity, azimuthal angle $\phi$, the orientation angle $\psi$, and the third order moments, \textit{skewness}, which is a measure of the asymmetry of the distribution and \textit{kurtosis}, which is a measure of whether the distribution is peaked or flat relative to a normal distribution. The calculation of the Hillas parameters with \textit{ctapipe} only requires the image of the shower (i.e. the number of photoelectrons in each pixel) and the information of the camera geometry.\\
   Besides the Hillas parameters, the time parameters are also calculated with other function in \textit{ctapipe}. This function requires the shower image and acamera geometry, plus the time position of the peak in the waveform of each pixel, which is obtained with the signal integrators mentioned in section \ref{sec:signalext}. The function performs a linear fit of the time positions versus the distance of the pixel from the vertical camera coordinate along the semimajor axis of the hillas elipse. The \textit{time gradient} is the slope of this line, and the \textit{intercept} is the free parameter of the linear fit. These two parameters are specially important for single telescope analysis, because they reflect the direction of development of the shower, which give information of the side of the ellipse where the source position is located in the camera frame.\\
Ultimately, there are two extra parameters calculated: The \textit{leakage2}, which indicates the percentage of the shower that falls in the two outer pixel rings of the camera; and the \textit{number of islands}, which accounts for the number of separated groups of pixels (a typical $\gamma$-ray shower will only have one island with elliptical form, but hadronic and heavier nuclei showers tend to produce messy light distributions with several islands of irregular shapes). Both parameters care calculated with respective functions from \textit{ctapipe}.

The calibration and image parametrization is performed \textit{cta-lstchain} using the scripts \textit{$lstchain\_data\_r0\_to\_dl1.py$}, \textit{$lstchain\_mc\_r0\_to\_dl1.py$}, depending on if the raw data used is simulated or real data. As is reflected in the script names, this steps reduces the data level from raw R0 data to DL1 (see table \ref{tab:CTAdatalevels}). In general, the image parameters can well describe the shower and therefore pixel wise information is not needed in further steps of the analysis. However, for testing and crosscheck purposes, \textit{cta-lstchain} scripts offer the possibility to store DL1 data with the full images, or only the parameters to save disk space.


\subsection{Reconstruction of energy and source position}

After the calibration and image parametrization, the image parameters should be used to extract information of the primary particle, whereas is a $\gamma$-ray or a background event (protons, electrons, heavier nuclei...). In \textit{cta-lstchain} the first step is to reconstruct the energy and arrival direction of the event. It can be easily seen that the energy is going to be directly proportional to the amount of Cherenkov light in the shower, hence the \textit{intensity} parameter will be the key of energy reconstruction.\\
The direction reconstruction is problematic in mono mode, because even knowing that the Hillas ellipse should point towards the source position in the camera frame, we do not know which side of the ellipse is correct (this is known as head-tail degeneracy). In stereo mode, this is solved because the source position will be in the cross point between the line which follows the semimajor axis of Hillas ellipses of all cameras, but for single telescope we must rely in other methods. In the case of \textit{cta-lstchain} we make use of a vector known as \textit{disp}. This is the vector going from the center of gravity of the ellipse to the source position.\\
Originally, the disp quantity could be parametrized in terms of the elongation of the image, meaning the ratio between \textit{width} and \textit{length}. The first parametrization was proposed by the Whipple collaboration \cite{1994dispwhipple}:

\begin{equation}
  Disp = \xi \cdot \left(1 - \frac{width}{length}  \right)
\end{equation}

Where $\xi$ is a factor dependent on the amount of photoelectrons in the shower image (the \textit{intensity} parameter)
And a more general parametrization was used for MAGIC-I \cite{2005DISPmagic}:

\begin{equation}
 Disp=A(intensity) + B(intensity) \cdot \frac{width}{length+\rho(intensity) \cdot leakage}  
\end{equation}

Where A and B and $\rho$ are the second order polynomial function of log(\textit{intensity}).

Instead of using a parametrization, we reconstruct the disp vector using the image parameters. The time parameters will be very important to reconstruct this quantity, because the Cherenkov light from the upper parts of the shower arrive before the light from later developed lower parts, giving the time gradient. The time gradient will therefore give information on which side of the ellipse is pointing to the source position.\\

The method used in \textit{cta-lstchain} for the reconstruction of these quantities, energy and disp vector, is based on a multidimensional regression technique relying on \glspl{rf}. \gls{rf} is a supervised learning algorithm which uses an ensemble of several decision trees (a \textit{bagging} technique). Decision trees are flow-chart-like structures where each internal node denotes a test on a selected feature. The result is a split in the dataset depending on the value of that feature. The best splitting criterion for regression is typically calculated using the \gls{mse}. For each node, the \gls{mse} of the two subsets is calculated for each feature and for each possible cut on that feature, until a minimum is reached. This step is repeated at each node until a condition is reached, typically that the \gls{mse} of the remaining data sample is below a threshold, or it has too few events to keep splitting. The termination nodes are also known as \textit{leaves}.
In the \gls{rf}, a number of decision trees are trained using a randomly selected subset of the train data (\textit{'bootstrapping'}) and the prediction of all the trees is averaged to reach the final result. Also, the features are always randomly permuted at each split. These two sources of randomness in the \gls{rf} prevent the typical problem of overfitting from too complicated decision trees. 

The \glspl{rf} for energy and disp reconstruction are trained using a set of \gls{mc} simulated $\gamma$ events triggering the \gls{lst}1, with diffuse arrival directions distributed in a 5º radius \gls{fov}. The set of simulated data is divided in two sets, one for training and other for testing. The freatures used for the splitting of the tree nodes are $log_{10}(intensity)$, \textit{width, length, x, y, psi, phi, width/length, skewness, kurtosis, r, time gradient, intercept, leakage} and \textit{number of islands}, where x, y and r are the coordinates and module of the vector from center of gravity of the Hillas ellipse to the center of the camera. The trained \gls{rf} is used later to reconstruct the desired values (energy and disp) in the test data.
For energy reconstruction, we actually reconstruct the $\log_{10}(E)$. In the case of the disp vector, we reconstruct the two components of the vector (\textit{disp\_dx, disp\_dy}) using the same \gls{rf}.\\
For the implementation of the \glspl{rf}, we use the Python package \textit{scikit-learn} \cite{2011scikit-learn}, a machine learning package which offers a large amount of tools for predictive data analysis. The class \textit{RandomForestRegressor} allow an easy training of the \glspl{rf}, which can be saved to be used later to fit any set of test data with the same format as the training. This class has a set of parameters that can be modified by the user to optimize the performance of the predictions. In \textit{cta-lstchain} these parameters can be modified by a configuration file. The most relevant parameters and their default values in \textit{cta-lstchain} are shown in table \ref{tab:RFpars}. 

\begin{table}
  \centering
  \begin{tabular}{|l|l|l|l|}
    \hline
    Parameter name & Value          & Value              & Description\\
                   & for regression & for classification &  \\ 
    \hline
    n\_estimators       & 150 & 100  & \small{Number of trees in the forest}\\
    criterion           & mse & gini & \small{Function to measure the quality of a split}\\
    max\_depth          & 50  & 100  & \small{Maximum depth of the tree}\\
    min\_samples\_split & 2   & 2    & \small{Minimum number of samples required to}\\
                        &     &      & \small{split an internal node} \\ 
    min\_samples\_leaf  & 2   & 2    & \small{Minimum number of samples to be at a}\\
                        &     &      & \small{leaf node} \\     
    max\_features       & all & all  & \small{Number of features to consider when looking} \\
                        &     &      & \small{for the best split}\\
    random\_state       & 42  & 42   & \small{Control the randomness of the} \\
                        &     &      & \small{bootstrapping and the sampling of features}\\
    n\_jobs             & 4   & 4    & \small{Number of jobs to run in parallel}\\
    \hline
  \end{tabular}
  \caption{Some parameters that can be configured for \textit{RandomForestRegressor} and \textit{RandomForestClassifier} classes, with the default values used in \textit{cta-lstchain}.}
  \label{tab:RFpars}
  \end{table}

\subsection{$\gamma$-hadron separation}

\section[Expectation-Maximization method for Hillas Parameters...]{Expectation-Maximization method for Hillas Parameters calculation without cleaning} \label{sec:EM}
\section{Sensitivity calculation}
\section{Results on real data}

\end{document}
